{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T21:00:31.809575Z",
     "start_time": "2019-10-31T21:00:25.215367Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Choice\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords \n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from pyLDAvis import sklearn as sklearn_lda\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "from nltk import tokenize\n",
    "import pyLDAvis\n",
    "from tqdm import tqdm\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tratamento dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T21:00:35.614719Z",
     "start_time": "2019-10-31T21:00:35.115139Z"
    }
   },
   "outputs": [],
   "source": [
    "df_data = pd.read_hdf('Carta_Capital_1000pag.hdf', key = 'hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T21:00:35.623716Z",
     "start_time": "2019-10-31T21:00:35.617718Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df_data.copy()\n",
    "df.columns = ['Data','Titulo','Texto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T21:00:35.718761Z",
     "start_time": "2019-10-31T21:00:35.627712Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_transform(data):\n",
    "    dict_data = {\n",
    "    'JAN': '01',\n",
    "    'FEV': '02',\n",
    "    'MAR': '03',\n",
    "    'ABR': '04',\n",
    "    'MAIO': '05',\n",
    "    'JUN': '06',\n",
    "    'JUL': '07',\n",
    "    'AGO': '08',\n",
    "    'SET': '09',\n",
    "    'OUT': '10',\n",
    "    'NOV': '11',\n",
    "    'DEZ': '12'\n",
    "}\n",
    "    \n",
    "    data = data.split()\n",
    "    data[1] = dict_data[data[1]]\n",
    "    data = '/'.join(data)\n",
    "    return dt.datetime.strptime(data,'%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T21:00:35.852867Z",
     "start_time": "2019-10-31T21:00:35.721759Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"Data\"] = df[\"Data\"].apply(data_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T21:00:37.783786Z",
     "start_time": "2019-10-31T21:00:37.759795Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>Bonecas negras ressaltam importância da divers...</td>\n",
       "      <td>[, , Lembrou-se da infância, em que os desenho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-09-03</td>\n",
       "      <td>“Bolsonaro não esconde o objetivo de destruir ...</td>\n",
       "      <td>[, , , , CartaCapital: Como o avanço das queim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-19</td>\n",
       "      <td>Damares publica decreto que extingue comitês d...</td>\n",
       "      <td>[, , O ministério informou que o decreto publi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>Especialistas avaliam fim de secretaria ligada...</td>\n",
       "      <td>[Por Júlia Daher, Tão logo assumiu o Ministéri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-03-28</td>\n",
       "      <td>Diversidade é “palavra da vez” e gera até cons...</td>\n",
       "      <td>[, A questão que fica é: se vivemos em um mund...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Data                                             Titulo  \\\n",
       "0 2019-10-11  Bonecas negras ressaltam importância da divers...   \n",
       "1 2019-09-03  “Bolsonaro não esconde o objetivo de destruir ...   \n",
       "2 2019-08-19  Damares publica decreto que extingue comitês d...   \n",
       "3 2019-04-12  Especialistas avaliam fim de secretaria ligada...   \n",
       "4 2019-03-28  Diversidade é “palavra da vez” e gera até cons...   \n",
       "\n",
       "                                               Texto  \n",
       "0  [, , Lembrou-se da infância, em que os desenho...  \n",
       "1  [, , , , CartaCapital: Como o avanço das queim...  \n",
       "2  [, , O ministério informou que o decreto publi...  \n",
       "3  [Por Júlia Daher, Tão logo assumiu o Ministéri...  \n",
       "4  [, A questão que fica é: se vivemos em um mund...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T21:00:37.949923Z",
     "start_time": "2019-10-31T21:00:37.901005Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.sort_values(by='Data',ascending=False).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T21:00:38.281999Z",
     "start_time": "2019-10-31T21:00:38.268986Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['Titulo'], keep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantidade de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T21:00:40.664775Z",
     "start_time": "2019-10-31T21:00:40.503232Z"
    }
   },
   "outputs": [],
   "source": [
    "df_word = df.copy()\n",
    "\n",
    "df_word['Texto'] = df_word['Texto'].apply(lambda x: ' '.join(x).split()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T21:00:42.375009Z",
     "start_time": "2019-10-31T21:00:42.364020Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_transform(words):\n",
    "    total = [x.lower() for x in words]\n",
    "    total = [re.sub(r'[,\\.!?()]', '', x) for x in total]\n",
    "    manual_list_stop_words = ['ser','sobre','ainda','se','além', 'outros','porque','assim','ter']\n",
    "    stop_words = stopwords.words('portuguese')\n",
    "    for i in manual_list_stop_words:\n",
    "        stop_words.append(i)\n",
    "    \n",
    "    total = [x for x in total if x not in stop_words]\n",
    "    total = [x for x in total if not re.search(r\"\\d\", x)]\n",
    "    \n",
    "    long_string = (\" \").join(total)\n",
    "    return long_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T21:00:49.200424Z",
     "start_time": "2019-10-31T21:00:42.504698Z"
    }
   },
   "outputs": [],
   "source": [
    "df_word['Texto'] = df_word['Texto'].apply(data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T21:00:49.213770Z",
     "start_time": "2019-10-31T21:00:49.200424Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    páreo eleitoral bolívia ganhou improvável azar...\n",
       "1    imagem estampada peito vez fazer referência gr...\n",
       "2    texto autoria bancada religiosa assinado verea...\n",
       "3    horas manhã domingo outubro francisco pronunci...\n",
       "4    espírito santo poderia inspirado papa convocar...\n",
       "Name: Texto, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word['Texto'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T18:37:25.465523Z",
     "start_time": "2019-10-24T18:37:25.454531Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_n_most_common_words(count_data, count_vectorizer, n):\n",
    "    import matplotlib.pyplot as plt\n",
    "    words = count_vectorizer.get_feature_names()\n",
    "    total_counts = np.zeros(len(words))\n",
    "    for t in count_data:\n",
    "        total_counts+=t.toarray()[0]\n",
    "    \n",
    "    count_dict = (zip(words, total_counts))\n",
    "    count_dict = sorted(count_dict, key=lambda x:x[1], reverse=True)[0:n]\n",
    "    words = [w[0] for w in count_dict]\n",
    "    counts = [w[1] for w in count_dict]\n",
    "    x_pos = np.arange(len(words)) \n",
    "    \n",
    "    plt.figure(2, figsize=(15, 10/1.6180))\n",
    "    plt.subplot(title=f'{n} most common words')\n",
    "    sns.set_context(\"notebook\", font_scale=1.25, rc={\"lines.linewidth\": 2.5})\n",
    "    sns.barplot(x_pos, counts, palette='husl')\n",
    "    plt.xticks(x_pos, words, rotation=90) \n",
    "    plt.xlabel('words')\n",
    "    plt.ylabel('counts')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T18:51:27.847225Z",
     "start_time": "2019-10-24T18:51:25.204453Z"
    }
   },
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "count_data = count_vectorizer.fit_transform(df_word['Texto'])\n",
    "                                               \n",
    "plot_n_most_common_words(count_data, count_vectorizer,60)                                               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T17:40:09.517589Z",
     "start_time": "2019-10-24T17:40:09.503597Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wordcloud_string = ' '.join(df_word['Texto'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T18:44:52.748813Z",
     "start_time": "2019-10-24T18:44:32.356878Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(max_words=1000,width=1600, height=700, contour_width=20)\n",
    "wordcloud.generate(wordcloud_string)\n",
    "plt.figure( figsize=(22,12), facecolor='k')\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "plt.savefig('worcloud_Pasztor.png', facecolor='k', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T18:03:49.571668Z",
     "start_time": "2019-10-24T18:03:28.759576Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(background_color=\"white\", max_words=1000, contour_width=20,width=1600, height=700, contour_color='steelblue')\n",
    "wordcloud.generate(wordcloud_string)\n",
    "wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T18:35:19.935396Z",
     "start_time": "2019-10-24T18:35:19.790355Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(wordcloud_string.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T19:10:08.660390Z",
     "start_time": "2019-10-24T19:10:08.237114Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('Textos_Carta_Capital.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T21:00:50.494792Z",
     "start_time": "2019-10-31T21:00:49.218769Z"
    }
   },
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "count_data = count_vectorizer.fit_transform(df_word['Texto'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T21:01:05.045283Z",
     "start_time": "2019-10-31T21:00:50.496776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics found via LDA:\n",
      "\n",
      "Topic #0:\n",
      "brasil governo país\n",
      "\n",
      "Topic #1:\n",
      "educação mulheres brasil\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    " \n",
    "# Helper function\n",
    "def print_topics(model, count_vectorizer, n_top_words):\n",
    "    words = count_vectorizer.get_feature_names()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"\\nTopic #%d:\" % topic_idx)\n",
    "        print(\" \".join([words[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "        \n",
    "# Tweak the two parameters below\n",
    "number_topics = 2\n",
    "number_words = 3\n",
    "# Create and fit the LDA model\n",
    "lda = LDA(n_components=number_topics, n_jobs=-1)\n",
    "lda.fit(count_data)\n",
    "# Print the topics found by the LDA model\n",
    "print(\"Topics found via LDA:\")\n",
    "print_topics(lda, count_vectorizer, number_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-31T21:01:33.779Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "LDAvis_prepared = sklearn_lda.prepare(lda, count_data, count_vectorizer)\n",
    "#pyLDAvis.save_html(LDAvis_prepared, 'ldavis_prepared_setences'+'.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
